{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PkeTIjziYN5"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "from tqdm import tqdm\n",
        "from typing import Tuple, List, Type, Dict, Any"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG0c8in0G3QS"
      },
      "source": [
        "from queue import Empty, Queue\n",
        "from threading import Thread\n",
        "import threading\n",
        "#Threads libraries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCCljdZy6xkn"
      },
      "source": [
        "# data augmentation library\n",
        "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
        "import imgaug.augmenters as iaa \n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-v7l1yjrmHk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37af4f3e-9ab7-4eef-fc10-2b9b96d3f2ef"
      },
      "source": [
        "#mount Drive for data transfer\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1aEuREpkPwc"
      },
      "source": [
        "with open('/content/drive/MyDrive/geo_kaggle/index.pkl', 'rb') as f:\n",
        "    data_index = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBpVON_WQ_-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e00dd8-b454-4e28-8f83-45639e2b36a8"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print('Using GPU', f'({torch.cuda.get_device_name(), torch.cuda.get_device_properties(device)})')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print('Using CPU')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU (('Tesla T4', _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKgbgU-MrmRQ"
      },
      "source": [
        "class thread_killer(object):    \n",
        "    \"\"\"Boolean object for signaling a worker thread to terminate\n",
        "    Once a thread is launched, it should be terminated at some moment.\n",
        "    In case the function of this thread is an infinite loop, one needs a mutex\n",
        "    for signaling a worker thread to break the loop.\n",
        "    The fuction will return, and the thread will be terminated.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.to_kill = False\n",
        "\n",
        "    def __call__(self):\n",
        "        return self.to_kill\n",
        "\n",
        "    def set_tokill(self, tokill):\n",
        "        self.to_kill = tokill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZFz8J4VIYa9"
      },
      "source": [
        "def threaded_batches_feeder(tokill, batches_queue, dataset_generator):\n",
        "    \"\"\"\n",
        "    Threaded worker for pre-processing input data.\n",
        "    tokill (thread_killer): an object that indicates whether a thread should be terminated\n",
        "    dataset_generator (Dataset): training/validation data generator\n",
        "    batches_queue (Queue): a limited size thread-safe Queue instance for train/validation data batches\n",
        "    \"\"\"\n",
        "    while tokill() == False:\n",
        "        for sample_batch in dataset_generator:\n",
        "            \n",
        "            batches_queue.put(sample_batch, block=True)\n",
        "            \n",
        "            if tokill() == True:\n",
        "                return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZAcbajoIsFC"
      },
      "source": [
        "def threaded_cuda_batches(tokill, cuda_batches_queue, batches_queue):\n",
        "    \"\"\"\n",
        "    Thread worker for transferring pytorch tensors into GPU. \n",
        "    batches_queue (Queue): the queue that fetches numpy cpu tensors.\n",
        "    cuda_batches_queue (Queue): the queue receiving numpy cpu tensors and transfering them to GPU memory.\n",
        "    \"\"\"\n",
        "    while tokill() == False:\n",
        "        sample_batch,labels,ids = batches_queue.get(block=True)\n",
        "        sample_batch = Variable(sample_batch).to(device)\n",
        "        labels = labels.to(device)\n",
        "        ids = ids.to(device)\n",
        "        \n",
        "        cuda_batches_queue.put((sample_batch,labels,ids), block=True)\n",
        "        if tokill() == True:\n",
        "            return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpYDNk41NSug"
      },
      "source": [
        "class Threadsafe_iter:\n",
        "    \"\"\"\n",
        "    Takes an iterator/generator and makes it thread-safe by\n",
        "    serializing call to the `next` method of given iterator/generator.\n",
        "    \"\"\"\n",
        "    def __init__(self, it):\n",
        "        self.it = it\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        with self.lock:\n",
        "            return next(self.it)\n",
        "\n",
        "def get_objects_id(objects_count):\n",
        "    \"\"\"Cyclic generator of paths indices\"\"\"\n",
        "    current_objects_id = 0\n",
        "    while True:\n",
        "        yield current_objects_id\n",
        "        current_objects_id  = (current_objects_id + 1) % objects_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMFoqCtSjmYL"
      },
      "source": [
        "class SkyDataset(Dataset):    \n",
        "    def __init__(self, \n",
        "                 data_frame, \n",
        "                 root_dir, \n",
        "                 transform=None, \n",
        "                 batch_size = 8, \n",
        "                 augment = True,\n",
        "                 seq = iaa.Sequential([iaa.GaussianBlur(sigma=(0, 5))],random_order=True), \n",
        "                 train = True, \n",
        "                 target = True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pkl_file (string): Path to the pkl file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "            batch_size (int, optional): batch size\n",
        "        \"\"\"\n",
        "        self.is_train = train\n",
        "        self.with_target = target\n",
        "        self.sky_data = data_frame\n",
        "        self.root_dir = os.path.abspath(root_dir)\n",
        "        self.transform = transform\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        self.objects_id_generator = Threadsafe_iter(get_objects_id(self.sky_data.shape[0]))\n",
        "        \n",
        "        self.lock = threading.Lock()\n",
        "        self.yield_lock = threading.Lock()\n",
        "        self.init_count = 0\n",
        "        self.augment = augment\n",
        "        self.cache = {}\n",
        "        \n",
        "        if self.augment:\n",
        "            # instantiate augmentations\n",
        "            self.seq = seq\n",
        "        \n",
        "    def __len__(self):                        \n",
        "        return self.sky_data.shape[0]\n",
        "    \n",
        "\n",
        "    def shuffle(self):\n",
        "        self.sky_data = shuffle(self.sky_data).reset_index(drop=True)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        while True:\n",
        "            with self.lock:\n",
        "                if (self.init_count == 0):\n",
        "                    if self.is_train:\n",
        "                        self.shuffle()\n",
        "                    self.imgs = []\n",
        "                    self.labels = []\n",
        "                    self.ids =[]\n",
        "                    self.init_count = 1\n",
        "            \n",
        "            \n",
        "            for obj_id in self.objects_id_generator:\n",
        "                add_str =''\n",
        "                if(self.with_target and self.sky_data.iloc[obj_id]['mission'] == 'AI49'):\n",
        "                    add_str = 'ai49-'\n",
        "                \n",
        "                \n",
        "                \n",
        "                img_name = os.path.join(self.root_dir, self.sky_data.iloc[obj_id]['mission'], 'snapshots', add_str + 'snapshots-'+str((self.sky_data.iloc[obj_id]['observations_dt']).date()), self.sky_data.iloc[obj_id]['jpg_filename'])\n",
        "                mask_name = os.path.join(self.root_dir, self.sky_data.iloc[obj_id]['mission'], 'masks', 'mask-id'+str(self.sky_data.iloc[obj_id]['devID'])+'.png') \n",
        "                if (self.with_target):\n",
        "                  label = int(self.sky_data.iloc[obj_id]['observed_TCC'])      \n",
        "                \n",
        "                  \n",
        "               \n",
        "               #Mask for photos, very expensive operation\n",
        "               # mask = plt.imread(mask_name)\n",
        "               # mask = np.where(mask == 255, np.ones_like(mask),mask*0)\n",
        "                       \n",
        "                \n",
        "                \n",
        "                img = plt.imread(img_name)\n",
        "                img = torchvision.transforms.Compose([\n",
        "                                                      torchvision.transforms.ToPILImage(), \n",
        "                                                    torchvision.transforms.Resize([256, 256]),\n",
        "                                                    torchvision.transforms.ToTensor()\n",
        "                                                    ])(img)\n",
        "                if self.transform:\n",
        "                    img = self.transform(img)\n",
        "                img= img.numpy()\n",
        "                                                 \n",
        "                if self.augment:\n",
        "                    img = self.seq(images = img)\n",
        "                                                \n",
        "                    # Concurrent access by multiple threads to the lists below\n",
        "                with self.yield_lock:\n",
        "                    if (len(self.imgs)) < self.batch_size:\n",
        "                        self.imgs.append(img)\n",
        "                        if self.with_target:\n",
        "                            self.labels.append(label)\n",
        "                        if self.with_target == False :\n",
        "                            self.ids.append(obj_id)\n",
        "                    if (obj_id + 1 == len(self)):\n",
        "                        yield (torch.Tensor(np.array(self.imgs)),(torch.Tensor(self.labels)).type(torch.LongTensor), torch.Tensor(self.ids))\n",
        "                        self.imgs = []\n",
        "                        self.labels = []\n",
        "                        self.jpg_names =[]\n",
        "                        break    \n",
        "                    if len(self.imgs) % self.batch_size == 0:\n",
        "                     \n",
        "                        yield (torch.Tensor(np.array(self.imgs)),(torch.Tensor(self.labels)).type(torch.LongTensor), torch.Tensor(self.ids))\n",
        "                        self.imgs = []\n",
        "                        self.labels = []\n",
        "                        self.ids =[]\n",
        "\n",
        "                    \n",
        "            # At the end of an epoch we re-init data-structures\n",
        "            with self.lock:\n",
        "                if self.is_train:\n",
        "                    self.sky_data = shuffle(self.sky_data)\n",
        "                self.init_count = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHBt9jZh0PnG"
      },
      "source": [
        "#funtion for training single epoch which is full data set divided to batches and transfered to GPU via multiple threads\n",
        "def train_single_epoch(model: torch.nn.Module,\n",
        "                       optimizer: torch.optim.Optimizer, \n",
        "                       loss_function: torch.nn.Module, \n",
        "                       STEPS_PER_EPOCH,\n",
        "                       train_cuda_batches_queue,\n",
        "                       data_len):\n",
        "    \n",
        "    model.train()\n",
        "    loss_sum = 0\n",
        "\n",
        "    for image_batch in tqdm(range(STEPS_PER_EPOCH), total=STEPS_PER_EPOCH):\n",
        "      \n",
        "        x,y, ids = train_cuda_batches_queue.get(block = True)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        hyp = model(x)\n",
        "       \n",
        "      \n",
        "        loss = loss_function(hyp, y)\n",
        "        loss.backward()\n",
        "        loss_sum += loss\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "    \n",
        "    return loss_sum/float(data_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Iig5xoX0az7"
      },
      "source": [
        "@torch.no_grad()\n",
        "# Validating of test data with accuracy metric, also transfered to GPU via multiple threads\n",
        "def validate_single_epoch(model: torch.nn.Module,\n",
        "                          loss_function: torch.nn.Module,                          \n",
        "                          STEPS_PER_EPOCH,\n",
        "                          test_cuda_batches_queue,\n",
        "                          data_len):\n",
        "    model.eval()\n",
        "    loss_sum = 0\n",
        "    accuracy = 0\n",
        "    \n",
        "    for image_batch in range(STEPS_PER_EPOCH):\n",
        "        \n",
        "        x,y,ids = test_cuda_batches_queue.get(block = True)\n",
        "\n",
        "        hyp = model(x)\n",
        "        loss = loss_function(hyp, y)\n",
        "        loss_sum += loss\n",
        "\n",
        "        y_pred = hyp.argmax(dim = 1, keepdim = True).to(device)\n",
        "    \n",
        "        accuracy += y_pred.eq(y.view_as(y_pred)).sum().item()\n",
        "\n",
        "    loss_avr = loss_sum / float(data_len)\n",
        "    accuracy_avr = 100 * accuracy / float(data_len)\n",
        "    \n",
        "    return {'loss' : loss_avr.item(), 'accuracy' : accuracy_avr}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOuVLUYg0dM_"
      },
      "source": [
        "def ploting_curves(loss, best_epoch):\n",
        "    \"\"\"\n",
        "    Plot loss evolution on training and validation sets\n",
        "    \"\"\"\n",
        "    # Plot learning loss curve\n",
        "    plt.plot(loss['train'], label = 'Training set')\n",
        "    plt.plot(loss['valid'], label = 'Val set')\n",
        "    plt.axvline(best_epoch, color = 'r', ls = '--', label = 'Best model')\n",
        "    plt.title('Loss evolution')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEEiiK9j0eq1"
      },
      "source": [
        "import math\n",
        "def train_model(model: torch.nn.Module, \n",
        "                train_data,\n",
        "                test_data,\n",
        "                loss_function: torch.nn.Module = torch.nn.CrossEntropyLoss(),\n",
        "                optimizer_class: Type[torch.optim.Optimizer] = torch.optim,\n",
        "                optimizer_params: Dict = {},\n",
        "                initial_lr = 0.01,\n",
        "                lr_scheduler_class: Any = torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "                lr_scheduler_params: Dict = {},\n",
        "                batch_size = 16,\n",
        "                s_eq = iaa.Sequential([iaa.GaussianBlur(sigma=(0, 5))],random_order=True),\n",
        "                max_epochs = 1000,\n",
        "                early_stopping_patience = 20):\n",
        "    # set to training mode\n",
        "  \n",
        "    # Here we instantiate queues and mutexes, and launch the threads that will preprocess the data and send it into GPU\n",
        "\n",
        "    \n",
        "    SkyData_train = SkyDataset(train_data, root_dir = '/content/drive/MyDrive/geo_kaggle', batch_size= batch_size, seq = s_eq)\n",
        "    SkyData_test = SkyDataset(test_data, root_dir = '/content/drive/MyDrive/geo_kaggle', batch_size= batch_size, augment= False, train = False)\n",
        "    \n",
        "    STEPS_PER_EPOCH_TRAIN = math.ceil(len(SkyData_train)/ float(batch_size)) \n",
        "    STEPS_PER_EPOCH_TEST = math.ceil(len(SkyData_test)/ float(batch_size)) \n",
        "\n",
        "    #Train data gpu and cpu queues\n",
        "    train_batches_queue_length = min(STEPS_PER_EPOCH_TRAIN, 2)    \n",
        "    train_batches_queue = Queue(maxsize=train_batches_queue_length)\n",
        "    train_cuda_batches_queue = Queue(maxsize=2)\n",
        "    train_thread_killer = thread_killer()\n",
        "    train_thread_killer.set_tokill(False)\n",
        "    train_preprocess_workers = 24\n",
        "\n",
        "    for _ in range(train_preprocess_workers):\n",
        "        thr = Thread(target=threaded_batches_feeder, args=(train_thread_killer, train_batches_queue, SkyData_train))\n",
        "        thr.start()\n",
        "\n",
        "    train_cuda_transfers_thread_killer = thread_killer()\n",
        "    train_cuda_transfers_thread_killer.set_tokill(False)\n",
        "    train_cudathread = Thread(target=threaded_cuda_batches, args=(train_cuda_transfers_thread_killer, train_cuda_batches_queue, train_batches_queue))\n",
        "    train_cudathread.start()\n",
        "\n",
        "    #Test data gpu and cpu queues\n",
        "    test_batches_queue_length = min(STEPS_PER_EPOCH_TEST, 2)    \n",
        "    test_batches_queue = Queue(maxsize=test_batches_queue_length)\n",
        "    test_cuda_batches_queue = Queue(maxsize=2)\n",
        "    test_thread_killer = thread_killer()\n",
        "    test_thread_killer.set_tokill(False)\n",
        "    test_preprocess_workers = 16\n",
        "\n",
        "    for _ in range(test_preprocess_workers):\n",
        "        thr = Thread(target=threaded_batches_feeder, args=(test_thread_killer, test_batches_queue, SkyData_test))\n",
        "        thr.start()\n",
        "\n",
        "    test_cuda_transfers_thread_killer = thread_killer()\n",
        "    test_cuda_transfers_thread_killer.set_tokill(False)\n",
        "    test_cudathread = Thread(target=threaded_cuda_batches, args=(test_cuda_transfers_thread_killer, test_cuda_batches_queue, test_batches_queue))\n",
        "    test_cudathread.start()\n",
        "\n",
        " \n",
        "    #Optimized cycle of model training\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr, **optimizer_params)\n",
        "    lr_scheduler = lr_scheduler_class(optimizer, **lr_scheduler_params)\n",
        "    \n",
        "    best_val_loss = None\n",
        "    best_epoch = None\n",
        "    loss_list = {'train': list(), 'valid': list()}\n",
        "    \n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        \n",
        "        print(f'Epoch {epoch}')\n",
        "    \n",
        "        train_loss =  train_single_epoch(model, optimizer, loss_function,STEPS_PER_EPOCH_TRAIN, train_cuda_batches_queue, len(SkyData_train))\n",
        "        \n",
        "        print('Validating epoch\\n')\n",
        "\n",
        "        val_metrics = validate_single_epoch(model, loss_function, STEPS_PER_EPOCH_TEST, test_cuda_batches_queue, len(SkyData_test))\n",
        "        loss_list['valid'].append(val_metrics['loss'])\n",
        "        print(f'Validation metrics: \\n{val_metrics}')\n",
        "\n",
        "        lr_scheduler.step(val_metrics['loss'])\n",
        "        torch.save(model, './alex_full.pth')\n",
        "        torch.save(model, '/content/drive/MyDrive/geo_kaggle/alex_full.pth')\n",
        "        \n",
        "        if best_val_loss is None or best_val_loss > val_metrics['loss']:\n",
        "            print(f'Best model yet, saving')\n",
        "            best_val_loss = val_metrics['loss']\n",
        "            best_epoch = epoch\n",
        "            torch.save(model, '/content/drive/MyDrive/geo_kaggle/best_alex_full.pth')\n",
        "            torch.save(model, './best_alex_full.pth')\n",
        "            \n",
        "        if epoch - best_epoch > early_stopping_patience:\n",
        "            print('Early stopping triggered')\n",
        "            ploting_curves(loss_list,best_epoch)\n",
        "            break\n",
        "    \n",
        "    #Emptifing and killing all used threads and queues\n",
        "    train_thread_killer.set_tokill(True)\n",
        "    train_cuda_transfers_thread_killer.set_tokill(True)\n",
        "    for _ in range(train_preprocess_workers):\n",
        "        try:\n",
        "            \n",
        "            train_batches_queue.get(block=True, timeout=1)\n",
        "            train_cuda_batches_queue.get(block=True, timeout=1)\n",
        "        except Empty:\n",
        "            pass\n",
        "\n",
        "    test_thread_killer.set_tokill(True)\n",
        "    test_cuda_transfers_thread_killer.set_tokill(True)\n",
        "    for _ in range(test_preprocess_workers):\n",
        "        try:\n",
        "            \n",
        "            test_batches_queue.get(block=True, timeout=1)\n",
        "            test_cuda_batches_queue.get(block=True, timeout=1)\n",
        "        except Empty:\n",
        "            pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUxOzgyJiR2x"
      },
      "source": [
        "# Function to evaluate target vaiable of huge dataset with the same structure as previous functions \n",
        "def GetTarget(data, model, batch = 100):\n",
        "    SkyData_test = SkyDataset(data, root_dir = '/content/drive/MyDrive/geo_kaggle_test', batch_size= batch, augment= False, train = False, target = False)\n",
        "    df =  pd.DataFrame(columns=['jpg_filename','TCC'])\n",
        "    STEPS_PER_EPOCH_TEST = math.ceil(len(SkyData_test)/ float(batch)) \n",
        "\n",
        "    size = 0\n",
        "    \n",
        "    test_batches_queue_length = min(STEPS_PER_EPOCH_TEST, 2)    \n",
        "    test_batches_queue = Queue(maxsize=test_batches_queue_length)\n",
        "    test_cuda_batches_queue = Queue(maxsize=2)\n",
        "    test_thread_killer = thread_killer()\n",
        "    test_thread_killer.set_tokill(False)\n",
        "    test_preprocess_workers = 32\n",
        "\n",
        "    for _ in range(test_preprocess_workers):\n",
        "        thr = Thread(target=threaded_batches_feeder, args=(test_thread_killer, test_batches_queue, SkyData_test))\n",
        "        thr.start()\n",
        "\n",
        "    test_cuda_transfers_thread_killer = thread_killer()\n",
        "    test_cuda_transfers_thread_killer.set_tokill(False)\n",
        "    test_cudathread = Thread(target=threaded_cuda_batches, args=(test_cuda_transfers_thread_killer, test_cuda_batches_queue, test_batches_queue))\n",
        "    test_cudathread.start()\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "   \n",
        "    for image_batch in tqdm(range(STEPS_PER_EPOCH_TEST), total=STEPS_PER_EPOCH_TEST):\n",
        "        \n",
        "        x,y,ids = test_cuda_batches_queue.get(block = True)\n",
        "\n",
        "        hyp = model(x)\n",
        "  \n",
        "        y_pred = hyp.argmax(dim = 1, keepdim = True).to(device)\n",
        "\n",
        "        ids = (ids).tolist()\n",
        "        y_pred = (y_pred).tolist()\n",
        "        for i in range(len(ids)):\n",
        "            df.loc[size] = [data.iloc[int(ids[i])]['jpg_filename'], y_pred[i][0]]\n",
        "            size += 1\n",
        "        \n",
        "    test_thread_killer.set_tokill(True)\n",
        "    test_cuda_transfers_thread_killer.set_tokill(True)\n",
        "    for _ in range(test_preprocess_workers):\n",
        "        try:\n",
        "            # Enforcing thread shutdown\n",
        "            test_batches_queue.get(block=True, timeout=1)\n",
        "            test_cuda_batches_queue.get(block=True, timeout=1)\n",
        "        except Empty:\n",
        "            pass\n",
        "\n",
        "    return df.drop_duplicates()\n",
        "         \n",
        "    \n",
        "        \n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48HpwZEeDHNG"
      },
      "source": [
        "#xarier initiation of weights\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform(m.weight)\n",
        "        m.bias.data.fill_(0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxKbgHXsqADO"
      },
      "source": [
        "#Transfer learining of Resnet512 and linear head\n",
        "class Pe_resnet512(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, \n",
        "                 input_resolution: Tuple[int, int] = (512, 512),\n",
        "                 input_channels: int = 1, \n",
        "                 hidden_layer_features: List[int] = [256, 256, 256],\n",
        "                 activation: Type[torch.nn.Module] = torch.nn.ReLU,\n",
        "                 num_classes: int = 9):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.input_resolution = input_resolution\n",
        "        self.input_channels = input_channels\n",
        "        self.hidden_layer_features = hidden_layer_features\n",
        "        self.activation = activation\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        resnet152 = torchvision.models.resnet152(pretrained=True, progress=False)\n",
        "        for param in resnet152.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        resnet152.fc = torch.nn.Sequential(torch.nn.Linear(2048, 128))\n",
        "\n",
        "        self.layer = torch.nn.Sequential(resnet152,\n",
        "                                         torch.nn.BatchNorm1d(128),\n",
        "                                         torch.nn.ReLU(),\n",
        "                                torch.nn.Linear(128,512),\n",
        "                                torch.nn.BatchNorm1d(512),\n",
        "                                torch.nn.ReLU(),\n",
        "                                torch.nn.Linear(512,1024),\n",
        "                                torch.nn.BatchNorm1d(1024),\n",
        "                                torch.nn.ReLU(),\n",
        "                                torch.nn.Linear(1024,9))\n",
        "    \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.layer(x)\n",
        "        \n",
        "        output = F.log_softmax(x, dim = 1)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxo7fA4I0nQn",
        "outputId": "2cd4cff6-53e5-437b-b713-f839e3040f7d"
      },
      "source": [
        "model =  torch.load('/content/drive/MyDrive/geo_kaggle/best_alex_full.pth')\n",
        "model.to(device)\n",
        "print(model)\n",
        "print('Total number of trainable parameters', \n",
        "      sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pe(\n",
            "  (layer): Sequential(\n",
            "    (0): AlexNet(\n",
            "      (features): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (4): ReLU(inplace=True)\n",
            "        (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (7): ReLU(inplace=True)\n",
            "        (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (9): ReLU(inplace=True)\n",
            "        (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (11): ReLU(inplace=True)\n",
            "        (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "      (classifier): Sequential(\n",
            "        (0): Dropout(p=0.5, inplace=False)\n",
            "        (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Dropout(p=0.5, inplace=False)\n",
            "        (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "      )\n",
            "      (fc): Sequential(\n",
            "        (0): Dropout(p=0.5, inplace=False)\n",
            "        (1): Linear(in_features=9261, out_features=4096, bias=True)\n",
            "        (2): ReLU()\n",
            "        (3): Dropout(p=0.5, inplace=False)\n",
            "        (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=4096, out_features=9, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Total number of trainable parameters 115856177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q_JKIM9YhtN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7321838c-e541-4fb7-ee55-05dd54d54c5a"
      },
      "source": [
        "#Read data\n",
        "data = pd.DataFrame(data_index)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(92077, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNqur78CvQ-j"
      },
      "source": [
        "df= data[data['observed_TCC'] == 8 ].sample(10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laVVab3pc3_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3664f8ec-eb6f-49fd-8913-a40c44319447"
      },
      "source": [
        "#Balance data\n",
        "data = pd.concat([df, data[data['observed_TCC'] != 8 ]], ignore_index=True).reset_index(drop = True)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(68788, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1-nNnMQdUTR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "1486c7f0-dc63-4725-c88f-39bb10d1e70c"
      },
      "source": [
        "plt.figure(figsize = (6, 6))\n",
        "sns.histplot(data, x = 'observed_TCC', hue = 'mission', multiple = 'stack')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa86c6d41d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAF0CAYAAADiqARmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3wU5dn/8c9FCGcVRVRIgkSKclIiRKiiYkvFqBWlUI8/RX6otY+UilVRah9TtVatttA+bQUVRR4FFFHx0FpaRUELChLPKEiBBGzBKCJa5NDr+WMn6wYCbIbszi77fb9e+3L3nntm7omab+ae2WvM3REREQmjUdQDEBGR7KUQERGR0BQiIiISmkJERERCU4iIiEhoChEREQmtcdQDSLcDDzzQO3bsGPUwRESyxqJFiz5297Z1Lcu5EOnYsSMLFy6MehgiIlnDzFbubJmms0REJDSFiIiIhKYQERGR0HLumohIoi1btlBVVcWmTZuiHkrGaNasGYWFheTn50c9FMkCChHJaVVVVeyzzz507NgRM4t6OJFzd6qrq6mqqqK4uDjq4UgW0HSW5LRNmzbRpk0bBUjAzGjTpo3OzCRpChHJeQqQ2vTzkPpQiIikwaxZs7jtttvqvd5xxx2XgtGINBxdExFJg0GDBjFo0KB6r/fKK6+kYDQiDUdnIiJ7aMWKFXTp0oWLL76Yww8/nAsuuIC//vWv9OvXj86dO/Pqq6/ywAMPMHLkSAAeffRRevToQc+ePTnxxBMBeOedd+jTpw8lJSUcddRRLF26FIBWrVoBsQve11xzDT169ODII49k+vTpAMyZM4eTTjqJoUOH0qVLFy644AL0tFJJJ52JiDSAZcuW8eijjzJp0iSOOeYYHn74YebNm8esWbO49dZbOeuss+J9b7rpJp577jkKCgpYv349AHfffTc//vGPueCCC9i8eTPbtm2rtf2ZM2dSUVHBG2+8wccff8wxxxwTD6DFixfzzjvv0L59e/r168fLL7/M8ccfn76Dl5ymMxGRBlBcXMyRRx5Jo0aN6N69OwMGDMDMOPLII1mxYkWtvv369ePiiy/mnnvuiYfFsccey6233srtt9/OypUrad68ea115s2bx3nnnUdeXh4HH3ww/fv357XXXgOgT58+FBYW0qhRI0pKSnbYn0gqKUREGkDTpk3j7xs1ahT/3KhRI7Zu3Vqr7913380tt9xCZWUlvXv3prq6mvPPP59Zs2bRvHlzTjvtNJ5//vlQ+87Ly9thfyKppBCph4KiDphZUq+Cog5RD1cy1Icffkjfvn256aabaNu2LZWVlSxfvpzDDjuMUaNGceaZZ/Lmm2/WWueEE05g+vTpbNu2jXXr1vHSSy/Rp0+fiI5A5Gu6JlIPa6oqOWdCcnfLTP+Bbs2Uul1zzTUsXboUd2fAgAH07NmT22+/nSlTppCfn88hhxzC2LFja60zePBg/v73v9OzZ0/MjDvuuINDDjmEJUuWRHQUIjGWa3dylJaWetjniZhZvUIk13622ei9996ja9euUQ8j4+jnIonMbJG7l9a1TNNZIiISmkJERERCU4iIiEhoChEREQlNISIiIqEpREREJDSFiEgGeOKJJzCz+Pc+VqxYgZlxww03xPt8/PHH5Ofnxws5lpeXc+eddwKxh2udfPLJlJeX8/7771NSUhJ/7bvvvowbNw6AN954g2OPPZYjjzySM844gw0bNqT5SGVvoxARSVCfqgQNWblg6tSpHH/88UydOjXeVlxczDPPPBP//Oijj9K9e/cd1t28eTNDhgyhd+/elJeXc8QRR1BRUUFFRQWLFi2iRYsWDB48GIBLLrmE2267jbfeeovBgwfzq1/9ag9/YpLr9I11kQT1qUqQjGQqF2zcuJF58+bxwgsvcMYZZ/Dzn/8cgBYtWtC1a1cWLlxIaWkp06dP5+yzz2bNmjXxdbdu3co555xD586d63zo1d/+9jc6derEoYceCsAHH3wQr/578sknc8opp3DzzTc3xKFKjtKZiEjEnnzyScrKyjj88MNp06YNixYtii8799xzmTZtGpWVleTl5dG+ffta695xxx00adIkPl21vWnTpnHeeefFP3fv3p0nn3wSiJ3ZVFZWpuCIJJcoREQiNnXqVM4991wgFhqJU1plZWXMnj2badOmcc455+yw7vHHH88rr7zCBx98sMOyzZs3M2vWLL7//e/H2yZNmsQf/vAHevfuzeeff06TJk1ScESSSzSdJRKhTz75hOeff5633noLM2Pbtm2YGVdccQUATZo0oXfv3tx11128++67zJo1q9b6J554IsOGDePUU09l3rx5tGvXLr7sT3/6E7169eLggw+Ot3Xp0oW//OUvQGxqK/Gai0gYChGRCM2YMYMLL7yQCRMmxNv69+9fa5rpJz/5Cf379+eAAw6ocxtDhgxh7dq1lJWV8eKLL9K6dWsgdoaTOJUFsHbtWg466CD+85//cMstt3D55Zen4Kgkl2g6SyRCU6dOjd85VWPIkCH88pe/jH/u3r07w4YN2+V2fvjDHzJ48GAGDRrEpk2b+OKLL5g9ezbf+973dtjf4YcfTpcuXWjfvj3Dhw9vuIORnKRS8PWgUvB7n+1LnhcUdWBNVcNdbG5fWMTqylUNtr10USl4SbSrUvCazhJJkI2/8EWipOksEREJTSEiIiKhKURERCQ0hYiIiISmEBERkdAUIiIZoK5S8M2bN6ekpISePXty3HHH8f777wMwZ84c9ttvP0pKSujatWu8YGONVatW0apVq3iZ+MrKSr71rW/RrVs3unfvzvjx49N7cLJX0y2+9ZCX3ySpqqw1fSX7dCwqYGXVmt13TNKhhe1ZUbl6t/0SS8HXhEKnTp2oqKgAYMKECdx6661MnjwZgBNOOIGnn36aL774gpKSEs444wx69eoFwFVXXcWpp54a33bjxo2566676NWrF59//jm9e/fm5JNPplu3bg12nJK7FCL1sG3LZvz+05Pqa8NVkygbraxak/S/42Qk89/BzkrBJ9qwYQP777//Du0tW7akd+/eLFu2jF69evHEE09QXFxMy5Yt433atWsXr6m1zz770LVrV1avXq0QkQahEBGJWF2l4Nu0acOHH35ISUkJn3/+OV9++SULFizYYd3q6mrmz5/Pz372MzZu3Mjtt9/O7Nmz41NZ21uxYgWLFy+mb9++qT4syRG6JiISsZ2Vgq+Zzvrwww8ZN24cl112WXyduXPncvTRRzNw4ECuu+46unfvTnl5OaNHj6ZVq1Z17mfjxo0MGTKEcePGse+++6b+wCQn6ExEJEK7KwVfY9CgQbWKJdZcE0m0YMECZsyYwbXXXsv69etp1KgRzZo1Y+TIkWzZsoUhQ4ZwwQUX7FCUUWRPKEREIpRMKXiAefPm0alTp11ua+7cufH35eXltGrVipEjR+LujBgxgq5du3LVVVc17AFIzkvZdJaZTTKztWb2dkLbAWY228yWBv/cP2g3M/utmS0zszfNrFfCOsOC/kvNbFhCe28zeytY57dmZqk6FpFU2VUp+JprIj179mTs2LHce++9ofbx8ssvM2XKFJ5//nlKSkooKSnh2WefbYjhi6SuFLyZnQhsBB509x5B2x3AJ+5+m5ldB+zv7mPM7DTgR8BpQF9gvLv3NbMDgIVAKeDAIqC3u39qZq8Co4AFwLPAb939T7sb156Wgq/P3VkqBZ/5ti95HtUtvplGpeAl0a5KwafsTMTdXwI+2a75TGBy8H4ycFZC+4MeMx9obWbtgFOA2e7+ibt/CswGyoJl+7r7fI/9pn4wYVsioa2oXI27N9grGwNEpD7SfXfWwe7+UfD+n0DNw58LgMRJ4KqgbVftVXW0i4hIGkV2i29wBpGW+R4zu8zMFprZwnXr1qVjlyIiKVdQ1AEzS+pVUNQhJWNI991Z/zKzdu7+UTAltTZoXw0UJfQrDNpWAydt1z4naC+so3+d3H0iMBFi10T27BBERDLDmqrKej2yOxXSfSYyC6i5w2oY8GRC+0XBXVrfBD4Lpr2eAwaa2f7BnVwDgeeCZRvM7JvBXVkXJWxLRETSJGVnImY2ldhZxIFmVgXcCNwGPGJmI4CVwNlB92eJ3Zm1DPgSGA7g7p+Y2c3Aa0G/m9y95mL9fwEPAM2BPwUvERFJo1TenXWeu7dz93x3L3T3+9y92t0HuHtnd/9OTSAEd2Vd4e6d3P1Id1+YsJ1J7v6N4HV/QvtCd+8RrDPSdT+tZLG6SsGbGb/73e/ifUaOHMkDDzwAwPz58+nbt2+8HHx5eTkQq8N11FFHUVJSQmlpKfPmzYuvX1ZWRuvWrfnud7+btuOSvZ9qZ4kkKOhQkPSFyqQuZnZI7qbBxFLwNQ466CDGjx/P5s2bd+g/bNgwJk6cSEVFBW+//TZnnx07qR8wYABvvPEGFRUVTJo0iUsuuSS+zjXXXMOUKVP28CckUpvKnogkWFO5huF/Hr77jkm6v+z+3fbZWSn4tm3b0q9fPyZPnsyll15aa521a9fGy7vn5eXFy7onFl/84osvSCzkMGDAAObMmbOnhyRSi85ERCJWVyn4GmPGjOHOO+9k27ZttdYZPXo0RxxxBIMHD2bChAls2rQpvuzxxx+nS5cunH766UyaNCltxyG5SSEiErGdlYIHOOyww+jbty8PP/xwrXX++7//m4ULFzJw4EAefvhhysrK4ssGDx7MkiVLeOKJJ/jZz36WnoOQnKXpLJEIJVMKfuzYsQwdOpT+/fvXWrdTp0788Ic/5NJLL6Vt27ZUV1fTpk2b+PITTzyR5cuX8/HHH3PggQem7Zgkt+hMRCRCNaXgV65cyYoVK6isrKS4uLhWKfguXbrQrVs3nnrqqXjbM898XeBz6dKl5OXl0bp1a5YtWxZvf/311/nqq69qBYtIQ9OZiEiEpk6dypgxY2q11ZSCT/TTn/6Uo48+Ov55ypQpjB49mhYtWtC4cWMeeugh8vLyeOyxx3jwwQfJz8+nefPmTJ8+PX5x/YQTTmDJkiVs3LiRwsJC7rvvPk455ZTUH6Ts1VJWCj5TqRS8JNq+5HlBhwLWVDZcKfj2Re1ZvSr7KvmqFHx2MLN6lT0J+ztpV6XgdSYikiAbf+GLREnXREREJDSFiIiIhKYQERGR0BQiIiISmkJERERCU4iIZIC6SsH36NEj/r558+aUlJRQUlLC5ZdfDsCXX37J6aefTpcuXejevTvXXXddZOOX3KUQEUlwaEHDloI/tCB8KfhEnTp1oqKigoqKCu6+++54+9VXX82SJUtYvHgxL7/8Mn/6k57NJuml74mIJFi1Zg0rLryowbbXccqDu+2zs1Lwu9OiRQu+9a1vAdCkSRN69epFVVXVHo1XpL50JiISsV2Vgq/xj3/8g6OPPpr+/fszd+7cHZavX7+ep556igEDBqRjyCJxChGRiO2qFDxAu3btWLVqFYsXL+bXv/41559/Phs2bIgv37p1K+eddx6jRo3isMMOS+vYc11BUYfkn3JZ1CHq4aaEprNEIpRMKfimTZvStGlTAHr37k2nTp344IMPKC2NlTK67LLL6Ny5M1deeWUkx5DL1lRV1qt21d5IZyIiEUqmFPy6deviTzZcvnw5S5cujZ9x3HDDDXz22WeMGzcukvGLKEREIjR16lQGDx5cq237UvAvvfQSRx11FCUlJQwdOpS7776bAw44gKqqKn7xi1/w7rvv0qtXL0pKSrj33nvTfQiS4zSdJZKgQ/v2Sd1RVZ/t7coLL7ywQ9uoUaMYNWpU/POQIUMYMmTIDv0KCwv1uAGJnEJEJMHK1SoFL1Ifms4SEZHQFCIiIhKaQkREREJTiIiISGgKERERCU0hIpIBdlUKvsaqVato1aoVd955Z7xt/Pjx9OjRg+7du+sLhxIJhYhIgg5FhzZoKfgORYcmtd/dlYIHuOqqqzj11FPjn99++23uueceXn31Vd544w2efvppli1btsc/A5H60PdERBJUVq3i8bt2rKIb1uCf9N5tn2RKwT/xxBMUFxfTsmXLeNt7771H3759adGiBQD9+/dn5syZXHvttQ02fpHd0ZmISMR2Vwp+48aN3H777dx444212nv06MHcuXOprq7myy+/5Nlnn61Vc0skHRQiIhHbXSn48vJyRo8eTatWrWq1d+3alTFjxjBw4EDKysooKSkhLy8vbeMWAU1niUQqmVLwCxYsYMaMGVx77bWsX7+eRo0a0axZM0aOHMmIESMYMWIEAGPHjqWwsDCqQ5EcpRARiVBNKfgJEybE2/r3719rWirxSYbl5eW0atWKkSNHArB27VoOOuggVq1axcyZM5k/f376Bi+CQkQkUlOnTmXMmDG12rYvBb8rQ4YMobq6mvz8fH7/+9/TunXrVAxTZKcUIiIJigo7JHVHVX22tyvJlIJPVF5eXutzXc9bF0knhYhIglWVK6MegkhW0d1ZIiISmkJERERCU4hIztMjZmvTz0PqQyEiOa1Zs2ZUV1frF2fA3amurqZZs2ZRD0WyhC6sS04rLCykqqqKdevWRT2UjNGsWTN9aVGSphCRnJafn09xcXHUwxDJWprOEhGR0CIJETMbbWbvmNnbZjbVzJqZWbGZLTCzZWY23cyaBH2bBp+XBcs7Jmzn+qD9fTM7JYpjERHJZWkPETMrAEYBpe7eA8gDzgVuB37j7t8APgVGBKuMAD4N2n8T9MPMugXrdQfKgD+YmUqYioikUVTXRBoDzc1sC9AC+Aj4NnB+sHwyUA78ETgzeA8wA/gfM7OgfZq7fwX8w8yWAX2Av6fpGEREIpWX34TpPzgu6b6pkPYQcffVZnYnsAr4N/AXYBGw3t23Bt2qgILgfQFQGay71cw+A9oE7YklSxPXERHZ623bshm///Sk+trwZ1Iyhiims/YndhZRDLQHWhKbjkrlPi8zs4VmtlC3coqINJwoLqx/B/iHu69z9y3ATKAf0NrMas6MCoHVwfvVQBFAsHw/oDqxvY51anH3ie5e6u6lbdu2bejjERHJWVGEyCrgm2bWIri2MQB4F3gBGBr0GQY8GbyfFXwmWP68x75ePAs4N7h7qxjoDLyapmMQERGiuSaywMxmAK8DW4HFwETgGWCamd0StN0XrHIfMCW4cP4JsTuycPd3zOwRYgG0FbjC3bel9WBERHJcJHdnufuNwI3bNS8ndnfV9n03Ad/fyXZ+AfyiwQcoIiJJ0TfWRUQkNIWIiIiEphAREZHQFCIiIhKaQkQkQxQUdcDMknoVFHWIergigJ4nIpIx1lRVcs6EV5Lqm2y9JJFU05mIiIiEphAREZHQFCIiIhKaQkREREJTiIiISGgKkSyiW0BFJNPoFt8soltARSTT6ExERERCU4iIiEhoChEREQlNISIiIqEpREREJDSFiIiIhKYQERGR0BQiIiISmkJERERCU4iIiEhoChEREQlNISIiIqEpREREJDSFiIiIhKYQERGR0BQiIiISmkJERERCU4iIiEhoChEREQlNISIiIqEpRGSvVVDUATNL6lVQ1CHq4YpkpcZRD0AkVdZUVXLOhFeS6jv9B8eleDQieyediYiISGg6ExGRrFRQ1IE1VZVJ9W1fWMTqylUNPoa8/CZJn8Xm5Tdp8P1nAoWIiGSlTJiu3LZlM37/6Un1teHPpGQMUdN0loiIhKYQERGR0JIKETPrl0ybiIjklmTPRH6XZJuIiOSQXV5YN7NjgeOAtmZ2VcKifYG8VA5MREQy3+7uzmoCtAr67ZPQvgEYmqpBiYhIdthliLj7i8CLZvaAu69M05hEcpK+cyDZKNnviTQ1s4lAx8R13P3bqRiUSC7Sdw4kGyUbIo8CdwP3AttSNxwREckmyd6dtdXd/+jur7r7oppX2J2aWWszm2FmS8zsPTM71swOMLPZZrY0+Of+QV8zs9+a2TIze9PMeiVsZ1jQf6mZDQs7HhERCSfZM5GnzOy/gMeBr2oa3f2TkPsdD/zZ3YeaWROgBTAW+Ju732Zm1wHXAWOAU4HOwasv8Eegr5kdANwIlAIOLDKzWe7+acgxZTzNmYtIpkk2RGr+yr8moc2Bw+q7QzPbDzgRuBjA3TcDm83sTOCkoNtkYA6xEDkTeNDdHZgfnMW0C/rOrgkyM5sNlAFT6zumbKE5cxHJNEmFiLsXN+A+i4F1wP1m1hNYBPwYONjdPwr6/BM4OHhfACSW6qwK2nbWvgMzuwy4DKBDBz18SESkoSQVImZ2UV3t7v5gyH32An7k7gvMbDyxqavE7bqZeYht18ndJwITAUpLSxtsuyIiuS7ZC+vHJLxOAMqBQSH3WQVUufuC4PMMYqHyr2CaiuCfa4Plq4GihPULg7adtYuISJokFSLu/qOE16XEfum3CrNDd/8nUGlmRwRNA4B3gVl8fe1lGPBk8H4WcFFwl9Y3gc+Caa/ngIFmtn9wJ9fAoE1ERNIk7EOpviB2bSOsHwEPBXdmLQeGEwu0R8xsBLASODvo+yxwGrAM+DLoi7t/YmY3A68F/W7ag7vFREQkhGSviTxF7G4siBVe7Ao8Enan7l5B7Nbc7Q2oo68DV+xkO5OASWHHISIieybZM5E7E95vBVa6e1UKxiMiIlkk2WsiLwJLiFXy3R/YnMpBiYhIdkj2yYZnA68C3yd2rWKBmakUvOxSQVEHzCypV0GRvr8jko2Snc76KXCMu68FMLO2wF+J3Z4rUqc1VZWcM+GVpPomW85FRDJLst8TaVQTIIHqeqwrIiJ7qWTPRP5sZs/xdV2qc4jdeisiIjlsd89Y/waxmlbXmNn3gOODRX8HHkr14EREJLPt7kxkHHA9gLvPBGYCmNmRwbIzUjo6ERHJaLu7rnGwu7+1fWPQ1jElIxIRkayxuxBpvYtlzRtyICIikn12N5210Mwudfd7EhvN7BJizwERyVh6EqRI6u0uRK4EHjezC/g6NEqBJsDgVA5MZE/pSZAiqbfLEHH3fwHHmdm3gB5B8zPu/nzKRyYiIhkv2cfjvgC8kOKxiIhIltG3zkVEJDSFiIiIhKYQERGR0BQiIiISmkJERERCU4iIiEhoChEREQlNISIiIqEl+1AqERHJMM3yGyVdsqdZfmrOGRQiIiJZatOW/zD8z8OT6nt/2f0pGYOms0REJDSFiIiIhKYQERGR0BQiIiISmkJERERC091ZkjJ6PK3I3k8hIimjx9NKKumPlMygEBGRrKQ/UjKDromIiEhoChEREQlNISIiIqEpREREJDSFiIjEFRR1wMx2+yoo6hD1UCVD6O4sEYlbU1XJORNe2W2/ZG+tlb2fzkRERCQ0hYiIiISmEBERkdAUIiIiEppCREREQlOIiIhIaAoREREJTSEiIiKhRRYiZpZnZovN7Ongc7GZLTCzZWY23cyaBO1Ng8/LguUdE7ZxfdD+vpmdEs2RiIjkrijPRH4MvJfw+XbgN+7+DeBTYETQPgL4NGj/TdAPM+sGnAt0B8qAP5hZXprGLiIiRBQiZlYInA7cG3w24NvAjKDLZOCs4P2ZwWeC5QOC/mcC09z9K3f/B7AM6JOeIxAREYjuTGQccC3wn+BzG2C9u28NPlcBBcH7AqASIFj+WdA/3l7HOrWY2WVmttDMFq5bt64hj0NEJKelPUTM7LvAWndflK59uvtEdy9199K2bduma7ciInu9KKr49gMGmdlpQDNgX2A80NrMGgdnG4XA6qD/aqAIqDKzxsB+QHVCe43EdUREUq5ZfqOkn9/eLH/vvBk27SHi7tcD1wOY2UnA1e5+gZk9CgwFpgHDgCeDVWYFn/8eLH/e3d3MZgEPm9mvgfZAZ+DVdB6LiOS2TVv+w/A/D0+q7/1l96d4NNHIpOeJjAGmmdktwGLgvqD9PmCKmS0DPiF2Rxbu/o6ZPQK8C2wFrnD3bekftohI7oo0RNx9DjAneL+cOu6ucvdNwPd3sv4vgF+kboQiIrIre+cknYiIpIVCREREQlOIiIhIaAoREREJLZPuzhKRiOXlN2H6D45Lqp9EL69JXtK3Duc1SU1pQYWIiMRt27IZv//03fZL9gt2klrbNm9jxYUXJdW345QHUzIGTWeJiEhoChEREQlN01n1oDo5IiK1KUTqQXVyRERq05/LIiISmkJERERCU4iIiEhoChEREQlNISIiIqEpREREJDSFiIiIhKYQERGR0BQiIiISmkJERERCU9kTkQyh2mySjRQiIhlCtdkkG+nPGRERCU0hIiIioWk6S0QkpEx4xnnUFCIiIiFlwjPOo6bpLBERCU0hIiIioSlEREQkNIWIiIiEpgvrWUTfaK4f/bxEUk8hkkX0jeb60c9LJPX055eIiISmEBERkdAUIiIiEppCREREQlOIiIhIaAoREREJTSEiIiKh6Xsi9aCyzyIitSlE6kFln0VEatN0loiIhKYzERHJSqqNlhkUIiKSlVQbLTMonkVEJDSFiIiIhJb26SwzKwIeBA4GHJjo7uPN7ABgOtARWAGc7e6fmpkB44HTgC+Bi9399WBbw4Abgk3f4u6T03ksInubZK8z6BqD1IjimshW4Cfu/rqZ7QMsMrPZwMXA39z9NjO7DrgOGAOcCnQOXn2BPwJ9g9C5ESglFkaLzGyWu3+a9iMS2Uske51B1xikRtpDxN0/Aj4K3n9uZu8BBcCZwElBt8nAHGIhcibwoLs7MN/MWptZu6DvbHf/BCAIojJgatoORjKavhwqknqR3p1lZh2Bo4EFwMFBwAD8k9h0F8QCpjJhtaqgbWftIoC+HCqSDpFNbJpZK+Ax4Ep335C4LDjr8Abc12VmttDMFq5bt66hNisikvMiCREzyycWIA+5+8yg+V/BNBXBP9cG7auBooTVC4O2nbXvwN0nunupu5e2bdu24Q5ERCTHpT1Egrut7gPec/dfJyyaBQwL3g8Dnkxov8hivgl8Fkx7PQcMNLP9zWx/YGDQJiIiaRLFNZF+wIXAW2ZWEbSNBW4DHjGzEcBK4Oxg2bPEbu9dRuwW3+EA7v6Jmd0MvBb0u6nmIrtINtKNAJKNorg7ax5gO1k8oI7+Dlyxk21NAiY13OhEoqMbASQb6RtDIiISmkJERERCU4iIiEhoKgWfRXThVeRr+v8hM+K0HAAAAAjnSURBVChEsoguvIp8Tf8/ZAZNZ4mISGg6E5GU0eNLs0+yU0SaHpIaChFJGT2+NPskO0Wk6SGpoT//REQkNIWIiIiEphAREZHQFCIiIhKaQkREREJTiIiISGgKERERCU0hIiIioSlEREQkNIWIiIiEphAREZHQFCIiIhKaQkREREJTiIiISGgKERERCU0hIiIioSlEREQkND3ZUFIm2Uet1vQVkeyjEJGUSfZRq6DHrYpkK01niYhIaAoREREJTSEiIiKhKURERCQ0hYiIiISmEBERkdAUIiIiEppCREREQlOIiIhIaAoREREJTSEiIiKhKURERCQ0hYiIiISmEBERkdAUIiIiEppCREREQlOIiIhIaAoREREJTSEiIiKhZX2ImFmZmb1vZsvM7LqoxyMikkuyOkTMLA/4PXAq0A04z8y6RTsqEZHckdUhAvQBlrn7cnffDEwDzox4TCIiOaNx1APYQwVAZcLnKqBvRGMREUmrpnl5dJzyYNJ9U8HcPSUbTgczGwqUufslwecLgb7uPnK7fpcBlwUfjwDeD7nLA4GPQ66bShpX/Whc9aNx1c/eOK5D3b1tXQuy/UxkNVCU8LkwaKvF3ScCE/d0Z2a20N1L93Q7DU3jqh+Nq340rvrJtXFl+zWR14DOZlZsZk2Ac4FZEY9JRCRnZPWZiLtvNbORwHNAHjDJ3d+JeFgiIjkjq0MEwN2fBZ5N0+72eEosRTSu+tG46kfjqp+cGldWX1gXEZFoZfs1ERERiZBCJAmZWlrFzCaZ2VozezvqsdQwsyIze8HM3jWzd8zsx1GPqYaZNTOzV83sjWBsP496TDXMLM/MFpvZ01GPJZGZrTCzt8yswswWRj2eGmbW2sxmmNkSM3vPzI7NgDEdEfycal4bzOzKqMcFYGajg//m3zazqWbWrMG2remsXQtKq3wAnEzsy4yvAee5+7uRDgwwsxOBjcCD7t4j6vEAmFk7oJ27v25m+wCLgLMy5OdlQEt332hm+cA84MfuPj/ioWFmVwGlwL7u/t2ox1PDzFYApe6eUd97MLPJwFx3vze4M7OFu6+Pelw1gt8bq4l9b21lxGMpIPbfejd3/7eZPQI86+4PNMT2dSayexlbWsXdXwI+iXocidz9I3d/PXj/OfAescoCkfOYjcHH/OAV+V9RZlYInA7cG/VYsoGZ7QecCNwH4O6bMylAAgOAD6MOkASNgeZm1hhoAaxpqA0rRHavrtIqGfFLMdOZWUfgaGBBtCP5WjBtVAGsBWa7eyaMbRxwLfCfqAdSBwf+YmaLgsoPmaAYWAfcH0wB3mtmLaMe1HbOBaZGPQgAd18N3AmsAj4CPnP3vzTU9hUikhJm1gp4DLjS3TdEPZ4a7r7N3UuIVTfoY2aRTgOa2XeBte6+KMpx7MLx7t6LWKXsK4Ip1Kg1BnoBf3T3o4EvgEy6VtkEGAQ8GvVYAMxsf2KzJ8VAe6Clmf2/htq+QmT3kiqtIl8Lrjc8Bjzk7jOjHk9dgumPF4CyiIfSDxgUXHuYBnzbzP432iF9LfgrFndfCzxObHo3alVAVcJZ5AxioZIpTgVed/d/RT2QwHeAf7j7OnffAswEjmuojStEdk+lVeohuHh9H/Ceu/866vEkMrO2ZtY6eN+c2M0SS6Ick7tf7+6F7t6R2H9bz7t7g/2VuCfMrGVwcwTBdNFAIPI7Ad39n0ClmR0RNA0AIr9xI8F5ZMhUVmAV8E0zaxH8/zmA2LXKBpH131hPtUwurWJmU4GTgAPNrAq40d3vi3ZU9AMuBN4Krj0AjA0qC0StHTA5uHOmEfCIu2fULbUZ5mDg8djvHRoDD7v7n6MdUtyPgIeCP+yWA8MjHg8QD9uTgR9EPZYa7r7AzGYArwNbgcU04LfXdYuviIiEpuksEREJTSEiIiKhKURERCQ0hYiIiISmEBERkdAUIiIiEppCRGQ7ZtYxk8rr1zCzOWZWupNlC4Ly46vMbF1COfKOZnZRUAL8raDW1NUJ610dlFOvMLPXzOyi9B2R7A30ZUORNDCzxu6+NVXbd/e+wX4uJla6fWTw+VTgSmCgu68xs6bARcGyy4l9Ma6Pu28ws32Bwakao+yddCYiOc/Mrgr+Un874SFCjc3soeCBRzPMrEXQ97bggVtvmtmdQVtbM3ss+Ev+NTPrF7SXm9kUM3sZmGJm882se8J+55hZaVBeZJLFHpi12MzODJY3N7NpwRgeB5qHOLzrgavdfQ2Au3/l7vcEy8YCP6wpkOnuG9x9coh9SA7TmYjkNDPrTaxkRl/AiJWtfxE4Ahjh7i+b2STgv8zsfmJ/qXdxd6+pwwWMB37j7vPMrAOxEjldg2XdiFXC/beZjQbOBm5MeHjXQjO7lVjNrP8fbPNVM/srsdIZX7p7VzM7iljZivrqQezBYNsf977APu6+PMQ2ReJ0JiK57njgcXf/Inhg1UzgBKDS3V8O+vxv0O8zYBNwn5l9D/gyWP4d4H+CWmGzgH2DUvgAs9z938H7R4ChwfuziVWfhVhhw+uC9ecAzYAOxB689L8A7v4m8GZDHrhIQ9CZiEjdti8q50Exzj7EqqAOBUYC3yb2x9g33X1T4gpB4cIvEjaw2syqg7OKc4DLa7oCQ9z9/TrW31PvAL2B57c7mA1mttHMDtPZiOwJnYlIrpsLnBWUyW5JbLpqLtDBzI4N+pwPzAvOLvYLKhKPBnoGy/9CrKosAGZWsov9TSf2FMP9grMLiE1//Sgo042ZHR20vxTsm+DhWUeFOL5fAr8ys0OC7TQxs0sSlv0+mNrCzFrp7iypL4WI5LTgefAPAK8Sux5yL/Ap8D6xJ/m9B+wP/BHYB3jazN4E5gFXBZsZBZQGF9vf5eszjLrMIPbckEcS2m4m9rz3N83sneAzwT5bBWO4iTqubSRxfM8C/wP8Ndj268C+Cdt/AXgtuKV5Lpn5iF7JYCoFLyIioelMREREQtOFdZEsY2YLgKbbNV/o7m9FMR7JbZrOEhGR0DSdJSIioSlEREQkNIWIiIiEphAREZHQFCIiIhLa/wE9iobkBYg0RgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFMVoBqG6k7J"
      },
      "source": [
        "data = shuffle(data).reset_index(drop = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9N7FU2yfWDl"
      },
      "source": [
        "#train-test random split\n",
        "test_data = data.loc[61000:68750,:].reset_index(drop=True)\n",
        "train_data = data.loc[:60999,:].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eumApmwk0uSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29f11e9-d30e-4d5b-a6e7-e2e5b688c3c1"
      },
      "source": [
        "train_model(model, \n",
        "            train_data,\n",
        "            test_data,\n",
        "            loss_function=torch.nn.CrossEntropyLoss(), \n",
        "            initial_lr=0.00005,\n",
        "            lr_scheduler_params = {'patience':2, 'threshold':0.0001},\n",
        "            s_eq = iaa.Sequential([\n",
        "                                  iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
        "                                   iaa.GaussianBlur(sigma=(0, 3.0)),\n",
        "                                   iaa.Flipud(0.5),\n",
        "                                   iaa.Affine(rotate = (-30,30),scale=(0.5, 1.5))                                                    \n",
        "                                  ]), \n",
        "            batch_size= 256)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/239 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 239/239 [24:13<00:00,  6.08s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating epoch\n",
            "\n",
            "Validation metrics: \n",
            "{'loss': 0.006056332029402256, 'accuracy': 46.83266675267707}\n",
            "Best model yet, saving\n",
            "Epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 239/239 [17:19<00:00,  4.35s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating epoch\n",
            "\n",
            "Validation metrics: \n",
            "{'loss': 0.005811895243823528, 'accuracy': 47.593858856921685}\n",
            "Best model yet, saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/239 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 239/239 [17:18<00:00,  4.35s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating epoch\n",
            "\n",
            "Validation metrics: \n",
            "{'loss': 0.00539693096652627, 'accuracy': 50.677331957166814}\n",
            "Best model yet, saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/239 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 239/239 [17:12<00:00,  4.32s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating epoch\n",
            "\n",
            "Validation metrics: \n",
            "{'loss': 0.005149856675416231, 'accuracy': 53.21893949167849}\n",
            "Best model yet, saving\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/239 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 239/239 [17:14<00:00,  4.33s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating epoch\n",
            "\n",
            "Validation metrics: \n",
            "{'loss': 0.005350863095372915, 'accuracy': 51.38691781705587}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/239 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 239/239 [17:19<00:00,  4.35s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating epoch\n",
            "\n",
            "Validation metrics: \n",
            "{'loss': 0.005891351029276848, 'accuracy': 49.23235711521094}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/239 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 239/239 [17:20<00:00,  4.35s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating epoch\n",
            "\n",
            "Validation metrics: \n",
            "{'loss': 0.006031247787177563, 'accuracy': 48.05831505612179}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/239 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 239/239 [17:48<00:00,  4.47s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating epoch\n",
            "\n",
            "Validation metrics: \n",
            "{'loss': 0.0055833375081419945, 'accuracy': 51.56753967230035}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/239 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 239/239 [18:18<00:00,  4.60s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating epoch\n",
            "\n",
            "Validation metrics: \n",
            "{'loss': 0.005598753225058317, 'accuracy': 51.864275577344856}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/239 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 62%|   | 148/239 [11:23<06:56,  4.58s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw5o56jVvbZQ"
      },
      "source": [
        "the_model = torch.load('/content/drive/MyDrive/geo_kaggle/best_alex_full.pth')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iozbj21upx-"
      },
      "source": [
        "print(the_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqmiABpPsIUR"
      },
      "source": [
        "with open('/content/drive/MyDrive/geo_kaggle_test/index.pkl', 'rb') as f:\n",
        "    data_index = pickle.load(f)\n",
        "data_valid = pd.DataFrame(data_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asiAgJH5tPGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1980e358-dd00-4a30-ea3a-4cb9792d4095"
      },
      "source": [
        "target = GetTarget(data_valid,the_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 270/270 [06:21<00:00,  1.41s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEDoTtcVLgX3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "9a6c6539-659a-4cd6-fd7c-c958130e66a4"
      },
      "source": [
        "target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jpg_filename</th>\n",
              "      <th>TCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>404863be-8c7b-4aba-9a11-70e61099068e.jpg</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1db7c21a-a0e7-48b1-8f9d-ab2e5124064d.jpg</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c1fd8fc6-d0a3-404b-b533-ea62b9a1b559.jpg</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70b7bf82-e6b6-48cd-8ce1-51cc4db4b914.jpg</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2a271026-72db-4fa6-9457-51ee47a51340.jpg</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26993</th>\n",
              "      <td>33b15d31-f370-4be3-9f96-eb70818c7b9d.jpg</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26994</th>\n",
              "      <td>18f65dbc-d80e-4177-8998-7eb026ad69a8.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26995</th>\n",
              "      <td>04cb832a-d8e5-4138-957f-5e011f7a3def.jpg</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26996</th>\n",
              "      <td>cd7bcaaf-f29b-41af-817b-c16ddef21fdc.jpg</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26998</th>\n",
              "      <td>3aab73f2-4dfb-4a50-8e6c-67f4f4d838a5.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26998 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   jpg_filename TCC\n",
              "0      404863be-8c7b-4aba-9a11-70e61099068e.jpg   8\n",
              "1      1db7c21a-a0e7-48b1-8f9d-ab2e5124064d.jpg   8\n",
              "2      c1fd8fc6-d0a3-404b-b533-ea62b9a1b559.jpg   8\n",
              "3      70b7bf82-e6b6-48cd-8ce1-51cc4db4b914.jpg   8\n",
              "4      2a271026-72db-4fa6-9457-51ee47a51340.jpg   8\n",
              "...                                         ...  ..\n",
              "26993  33b15d31-f370-4be3-9f96-eb70818c7b9d.jpg   8\n",
              "26994  18f65dbc-d80e-4177-8998-7eb026ad69a8.jpg   1\n",
              "26995  04cb832a-d8e5-4138-957f-5e011f7a3def.jpg   8\n",
              "26996  cd7bcaaf-f29b-41af-817b-c16ddef21fdc.jpg   8\n",
              "26998  3aab73f2-4dfb-4a50-8e6c-67f4f4d838a5.jpg   4\n",
              "\n",
              "[26998 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyjHIFyo6Q_i"
      },
      "source": [
        "target.to_csv('/content/alex_full_try.csv', sep=',' , index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVmHfrK1Je6H"
      },
      "source": [
        "Due to parallel loading of data some objects are not evaluated (usually less than 1 per cent)\n",
        "Here are their names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdWbyMD2FR6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6be7ab4-fca8-422f-ec8c-301401223300"
      },
      "source": [
        "(pd.concat([target['jpg_filename'], data_valid['jpg_filename']])).drop_duplicates(keep=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26997    1b4a02b2-1706-4f40-b9a1-437e49a857e7.jpg\n",
              "26999    0824f176-2f23-4e16-9fdf-6a411da2979a.jpg\n",
              "Name: jpg_filename, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bbgygtAdZAi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}